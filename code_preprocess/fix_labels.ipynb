{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0b90a361e62b375168f9f59a2709b439bc2aa00630d9804b6e8ee92c8b4d50568",
   "display_name": "Python 3.8.10 64-bit ('szeged': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "b90a361e62b375168f9f59a2709b439bc2aa00630d9804b6e8ee92c8b4d50568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from humannotator import Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "source": [
    "# Load Szeged Uncertainty Corpus\n",
    "## token-level, multi-class labels\n",
    "source `merged_data` file: [http://people.rc.rit.edu/~bsm9339/corpora/szeged_uncertainty/](http://people.rc.rit.edu/~bsm9339/corpora/szeged_uncertainty/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data')"
   ]
  },
  {
   "source": [
    "The following cell parses the tsv file line by line and extracts each feature into a dictionary (the key is the feature name, the value is the feature value); the dictionary is then loaded into a pandas DataFrame so that each feature is in its own column. This procedure is necessary (in contrast to loading the table directly into pandas df) because --\n",
    "- the features are not arranged in a fixed order in the tsv file\n",
    "- if a feature is not relevant for a specific row, it is not mentioned at all; this results in varying number of columns for each row"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "with open(path / 'merged_data.tsv', 'r', encoding='utf8') as f:\n",
    "    tsvreader = csv.reader(f, delimiter='\\t', quoting=3)\n",
    "    for idx, line in enumerate(tsvreader):\n",
    "        if not line:\n",
    "            continue\n",
    "        row = dict()\n",
    "        row['sen_tok_id'] = line[0]\n",
    "        row['words'] = line[1]\n",
    "        row['stem'] = line[2]\n",
    "        row['pos'] = line[3]\n",
    "        row['labels'] = line[5]\n",
    "        for colitem in line[6:]:\n",
    "            if colitem.startswith('L_'):\n",
    "                continue\n",
    "            regex = re.compile('([a-z]+_(?:-*\\d|[a-z]+))')\n",
    "            r = regex.split(colitem, maxsplit=1)\n",
    "            row[r[1]] = r[2][1:-4]\n",
    "        data[idx] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "szeged = pd.DataFrame.from_dict(data, orient='index'\n",
    ").assign(\n",
    "    sentence_id=lambda df: df.sen_tok_id.str.extract(r'sent(\\d+)token', expand=False).astype(int),\n",
    "    sentence = lambda df: df.groupby('sentence_id').words.transform(lambda s: s.str.cat()),\n",
    ").drop(labels=['sen_tok_id', 'lemma_0', 'pos_0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C    1821704\n",
       "E       8213\n",
       "U       5740\n",
       "I       1930\n",
       "D       1408\n",
       "N        831\n",
       "Name: labels, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "szeged.labels.value_counts()"
   ]
  },
  {
   "source": [
    "# Deduplicate sentences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "szeged = szeged.assign(\n",
    "    first_sent_id = lambda df: df.groupby('sentence').sentence_id.transform('min')\n",
    ").query(\"sentence_id == first_sent_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C    1055973\n",
       "E       4174\n",
       "U       3536\n",
       "D        915\n",
       "I        881\n",
       "N        501\n",
       "Name: labels, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "szeged.labels.value_counts()"
   ]
  },
  {
   "source": [
    "# Fix labels (re-label U class)\n",
    "source `json` files: [http://people.rc.rit.edu/~bsm9339/corpora/szeged_uncertainty/](http://people.rc.rit.edu/~bsm9339/corpora/szeged_uncertainty/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Step 1: Collect all uncertainty cues from the json files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing bio_bmc\n",
      "Processing bio_fly\n",
      "Processing bio_hbc\n",
      "Processing factbank\n",
      "Processing wiki\n"
     ]
    }
   ],
   "source": [
    "jpath = path / 'json'\n",
    "\n",
    "utexts = list()\n",
    "utypes = list()\n",
    "utails = list()\n",
    "cue_dict = dict()\n",
    "\n",
    "for filename in jpath.glob('*.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"Processing {filename.stem}\")\n",
    "    for item in data['Annotation']['DocumentSet']['Document']:\n",
    "        for dictionary in item['DocumentPart']:\n",
    "            if not isinstance(dictionary, dict) or dictionary.get('Sentence') is None:\n",
    "                continue\n",
    "            if isinstance(dictionary['Sentence'], list):\n",
    "                for sent_dict in dictionary['Sentence']:\n",
    "                    ccue = sent_dict.get('ccue')\n",
    "                    if ccue is None:\n",
    "                        continue\n",
    "                    ccue = [ccue] if isinstance(ccue, dict) else ccue\n",
    "                    for item in ccue:\n",
    "                        utypes.append(item['@type'])\n",
    "                        utexts.append(item['#text'])\n",
    "                        utails.append(item['#tail'])\n",
    "\n",
    "cue_dict['utext'] = utexts\n",
    "cue_dict['utype'] = utypes\n",
    "cue_dict['utail'] = utails\n",
    "\n",
    "cues = pd.DataFrame.from_dict(cue_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['speculation_modal_probable_', 'speculation_hypo_investigation _',\n",
       "       'speculation_hypo_doxastic _', 'speculation_hypo_condition _',\n",
       "       'speculation_modal_possible_'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "cues.utype.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9176, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "cues.shape"
   ]
  },
  {
   "source": [
    "## Step 2: explode cues with multiple tokens\n",
    "### so that each token has its own row (like in the szeged df)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9603, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "cues = cues.assign(\n",
    "    list_text = lambda df: df.utext.str.split(),\n",
    "    len_text = lambda df: df.list_text.apply(len),\n",
    ").explode('list_text')\n",
    "\n",
    "cues.shape"
   ]
  },
  {
   "source": [
    "## Step 3: convert label names"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"speculation_modal_possible_\": \"E\", \n",
    "    \"speculation_modal_probable_\": \"E\", \n",
    "    \"speculation_hypo_doxastic _\": \"D\", \n",
    "    \"speculation_hypo_investigation _\": \"I\", \n",
    "    \"speculation_hypo_condition _\": \"N\",\n",
    "}\n",
    "\n",
    "cues = cues.assign(\n",
    "    new_label = lambda df: df.utype.map(label_map),\n",
    "    u = 'U',\n",
    "    text_n_tail = lambda df: df.utext + df.utail,\n",
    ")"
   ]
  },
  {
   "source": [
    "## Step 4: re-label based on matched sentence text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NONMATCHED = list()\n",
    "def add_sent_id(row, sent_df):\n",
    "    \"\"\"\n",
    "    Find the sentence(s) in `sent_df` that contain the cue and its tail.\n",
    "    If only one sentence is matched - return its sentence_id.\n",
    "    If multiple sentences or no sentences are matched - add row to `UNMATCHED`.\n",
    "    \"\"\"\n",
    "    search_str = row.text_n_tail.replace(\" \", \"\")\n",
    "    crit = sent_df.sentence.str.contains(search_str, regex=False)\n",
    "    if crit.sum() == 1:\n",
    "        return sent_df.loc[crit].sentence_id.iloc[0]\n",
    "    elif crit.sum() > 1:\n",
    "        row['matched_ids'] = sent_df.loc[crit].sentence_id.to_list()\n",
    "    NONMATCHED.append(row.copy())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent_df = szeged.query(\"labels == 'U'\").drop_duplicates(subset=['sentence'])\n",
    "cues['sentence_id'] = cues.apply(lambda row: add_sent_id(row, sent_df), axis=1)\n",
    "not_matched = pd.concat(NONMATCHED, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The sentence_id was matched for \n3051 out of 3536 U-labeled tokens in szeged df. \nThese tokens can now be re-labeled with the correct label from the json.\n\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"The sentence_id was matched for \n",
    "{len(cues.query(\"sentence_id.notna()\"))} out of {len(szeged.query(\"labels == 'U'\"))} U-labeled tokens in szeged df. \n",
    "These tokens can now be re-labeled with the correct label from the json.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "szeged = szeged.merge(\n",
    "    cues[['list_text', 'new_label', 'u', 'sentence_id']],\n",
    "    how='left',\n",
    "    left_on=['words', 'labels', 'sentence_id'],\n",
    "    right_on=['list_text', 'u', 'sentence_id'],\n",
    ")\n",
    "\n",
    "szeged = szeged.drop(['list_text', 'u'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "szeged.new_label = szeged.new_label.fillna(szeged.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C    1055973\n",
       "E       6029\n",
       "D       1417\n",
       "I       1263\n",
       "N        860\n",
       "U        624\n",
       "Name: new_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "szeged.new_label.value_counts()"
   ]
  },
  {
   "source": [
    "## Step 5: fix non-matched"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (a) check whether all appearances of a cue in the corpus are assigned the same label; if so, it can be safely re-labeled"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ambig_check(row, cues_df):\n",
    "    return cues_df.query(f'utext == \"{row.utext}\"').new_label.unique()\n",
    "\n",
    "not_matched['possible_labels'] = not_matched.apply(lambda row: ambig_check(row, cues), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique non-matched cues: 286\nAlways have the same label: 267\n\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique non-matched cues: {not_matched.utext.nunique()}\")\n",
    "print(f\"\"\"Always have the same label: {not_matched.assign(n_p_labels=lambda df: df.possible_labels.apply(len)).query(\"n_p_labels==1\").utext.nunique()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unambig = not_matched.assign(n_p_labels=lambda df: df.possible_labels.apply(len)\n",
    ").query(\"n_p_labels==1\"\n",
    ")[['utext', 'list_text', 'new_label', 'u']\n",
    "].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "szeged = szeged.merge(\n",
    "    unambig,\n",
    "    how='left',\n",
    "    left_on=['words', 'new_label'],\n",
    "    right_on=['list_text', 'u'],\n",
    ")\n",
    "\n",
    "szeged = szeged.drop(['utext', 'list_text', 'u'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "szeged.new_label_y = szeged.new_label_y.fillna(szeged.new_label_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C    1055973\n",
       "E       6455\n",
       "D       1538\n",
       "I       1493\n",
       "N        908\n",
       "U        102\n",
       "Name: new_label_y, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "szeged.new_label_y.value_counts()"
   ]
  },
  {
   "source": [
    "### (b) fix remaining U labels manually"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "szeged.rename({'labels': 'original_labels'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = szeged.assign(\n",
    "    sent_w_space = lambda df: df.groupby('sentence_id').words.transform(lambda s: s.str.cat(sep=' ')),\n",
    ").query(\"new_label_y == 'U'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['E', 'D', 'I', 'N']\n",
    "# a = Annotator(fix[['words', 'sentence_id', 'sent_w_space']], name='Uncertainty labels')\n",
    "# a.tasks['Label'] = labels, None, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.save(path / 'manual_fix_annot.pkl')\n",
    "b = Annotator.load(path / 'manual_fix_annot.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = fix.merge(\n",
    "    b.annotated[['Label']],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "szeged = szeged.merge(\n",
    "    fix[['words', 'original_labels', 'sentence_id', 'Label']],\n",
    "    how='left',\n",
    "    left_on=['words', 'original_labels', 'sentence_id'],\n",
    "    right_on=['words', 'original_labels', 'sentence_id'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "szeged.Label = szeged.Label.fillna(szeged.new_label_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C    1055973\n",
       "E       6525\n",
       "D       1546\n",
       "I       1496\n",
       "N        931\n",
       "Name: Label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "szeged.Label.value_counts()"
   ]
  },
  {
   "source": [
    "# Save fixed Szeged Uncertainty Corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = szeged.rename({'Label': 'labels'}, axis=1\n",
    ").drop(['original_labels', 'sentence', 'first_sent_id', 'new_label_x', 'new_label_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_pickle(path / 'szeged_fixed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}